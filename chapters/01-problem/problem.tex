\chapter{Огляд стану проблеми та основні поняття}\label{ch:01}

\section{Розвиток та застосування кластеризації}
    Термін ,,кластерний аналіз'', вперше використаний Тріоном у \cite{Tryon:Cluster:1939}, означає набір підходів та алгоритмів, призначених для об'єднання схожих об'єктів у групи. Ця технологія знайшла своє застосування в цілій низці галузей наук та є необхідною частиною більшості сучасних засобів аналізу даних.
 
    В 1959 радянський вчений Терентьєв розробив так званий ,,метод кореляційних плеяд'' \cite{Terentyev}, покликаний здійснювати групування на базі корелюючих ознак об'єктів. Займаючись вивченням кореляцій між різними ознаками озерної жаби, він об'єднав їх в групи за абсолютною величиною коефіцієнту кореляції. Таким чином він отримав дві групи ознак -- ознаки із великим та з малим значенням кореляції. Терентьєв назвав ці групи ,,кореляційними плеядами'' та опублікував декілька методів їх аналізу. Це посприяло розвитку методів кластеризації за допомогою графів.
    
    На початку 50х років також вийшли публікації Р.~Льюїса, Е.~Фікса та Дж.~Ходжеса, присвячені ієрархічним алгоритмам кластеризації. Відчутний поштовх технології кластерного аналізу дали роботи Розенблатта про розпізнаючий пристій ,,перцептрон''. Ці роботи поклали початок теорії ,,розпізнавання без вчителя''. Поштовхом до розробки методів кластеризації стала публікація \cite{SokalSneath}. В своїй роботі автори Сокел та Сніт виходили з того, що для створення ефективних біологічних класифікацій процедура кластеризації повинна використовувати всеможливі показники, що характеризують досліджувані організми, проводити оцінку ступеня схожості між цими організмами, та забезпечувати розташування схожих організмів в одну групу. При цьому сформовані групи повинні бути досить локальними, тобто схожість організмів всередині групи повинна бути більшою, ніж схожість між організмами, що належать різним групам. Подальший аналіз таких груп допоможе вияснити, чи відповідають вони реальним біологічним класифікаціям. Сокел та Сніт вважали, що виявлення структури розподілу об'єктів у групи допоможе встановити процес утворення цих груп.
    
    В середині сімдесятих з'явилась також низка робіт, присвячених методам аналізу якості здійсненої кластеризації. Індекси Данна \cite{Dunn} та  Девіса-Боулдіна \cite{DavisBouldin} дозволяють чисельно оцінити якість розбиття даних на кластери.

\section{Типові задачі}
    Із кластерів, що повертаються в результаті роботи алгоритмів таксономії, можна виділити типових представників , і надалі працювати не з кожним об'єктом великого масиву, а лише з цими представниками. Це дозволяє суттєво спростити аналіз даних. Кластеризація часто стає складовою якоїсь більшої задачі, інструментом підготовки даних для її розв'язання. Такі задачі завжди пов'язані із пошуком та виділенням змістовних структур із великих масивів даних. 

    До них можна віднести задачі сегментування та розпізнавання зображень, мовлення, пошуку прихованих закономірностей в даних. На практиці такі задачі виникають при розв'язуванні проблем, що виникають в медицині, соціології, економіці та низці інших сфер діяльності людини. 
     медицині, наприклад, техніка сегментування зображення дозволяє виділяти на томограмах окремі області і на підставі їх форми та забарвлення приймати ставити діагноз. 
    В біології використовуються техніки кластеризації для виявлення взаємопов'язаних груп генів та їх впливу на живі організми. 
    Кластеризація успішно застосовується у маркетингових дослідженнях для виявлення зв'язків між різними групами споживачів та потенційних покупців, цільових аудиторій, та оптимального позиціонування нової продукції. 
    В соціологічних дослідженнях використовується кластеризація даних, отриманих з різних джерел, для спрощення їх подальшого аналізу. 

    У своїй праці \cite{Zagorujko} Загоруйко описує одну із таких задач. Новосибірські вчені вивчали причини переселення людей з сіл в міста. Були вислані експедиції в навколишні села, жителям яких задавали приблизно сто анкетних питань, що стосувались віку, сімейного становища, освіти та ін. Після завершення опитування дослідники постали перед необхідністю аналізувати більш ніж сім тисяч анкет, що містили понад сто питань кожна. 
    Ці дані було введено в програму таксономії, котра повернула сім великих таксонів, середні характеристики яких дозволили дати зібраним даним змістовну інтерпретацію. Наприклад, виділився кластер, що містив переважно жінок середнього віку, котрі мали дорослих дітей в місті. Очевидно, представниці цього таксону, названого дослідниками ,,бабусі'', їхали в місто доглядати за своїми внуками. Решту таксонів опрацьовано аналогічно.
    
    Перед процедурою кластеризації часто дані буває необхідно підготувати. В практиці нормою є випадки, коли для деяких об'єктів бракує частини атрибутів -- в такому разі перед кластеризацією необхідно здійснити передбачення цих атрибутів, користуючись наявною інформацією. Також значення атрибутів об'єктів необхідно нормувати.

\section{Основні поняття та означення}
    Дамо математичне означення кластеризації. Нехай $D$ -- множина об'єктів. 
    \begin{definition}
        \emph{Кластеризацією} $C = \{C \mid C \subseteq D\}$ називається таке розбиття $D$ на множини, 
        для якого виконується $\cup_{C_i \in C} = D$ і $\forall C_i, C_j \in C : C_i \cap C_{j \neq i} = \emptyset$. 
        Множини $C_i$ називаються кластерами.
    \end{definition}
    Як вже згадувалось раніше, задача кластеризації полягає в знаходженні такого розбиття $C$, щоб схожі між собою об'єкти належали до одного кластера, а не схожі - до різних. Необхідно визначити спосіб обчислення схожості об'єктів.
    Для цього на просторі об'єктів вводиться певна метрика, геометричний зміст якої -- відстань між об'єктами. Вона використовується як величина, обернена до міри схожості між об'єктами. На даний момент розроблено і широко застосовується наступний набір метрик:
    \begin{itemize}
        \item {евклідова відстань} 
            \[ 
                \rho(x, x') = \sqrt{ \sum_{i=1}^n (x_i - x_i')^2}
            \]
        \item {квадрат евклідової відстані} 
            \[
                \rho(x, x') = \sum_{i=1}^n (x_i - x_i')
            \]            
            (використовується для надання більшої ваги об'єктам, розташованим далеко один від одного)
        \item {манхеттенська відстань} 
            \[
                \rho(x, x') = \sum_{i=1}^n \mid x_i - x_i' \mid
            \]
        \item {відстань Чебишева}
            \[
                \rho(x, x') = max(\mid x_i - x_i' \mid )
            \]            
            ця метрика дозволяє розрізнити об'єкти, якщо вони відрізняються лише одною координатою
    \end{itemize}
    
    
    
\section{Алгоритми кластеризації}
    На даний момент значного розвитку набула ціла низка різноманітних алгоритмів кластеризації. Їх можна розділити на групи за різними ознаками:
    \begin{itemize}
        \item спосіб групування (роздільне, ієрархічне)
        \item визначеність 
        \item чутливість до форми кластерів 
    \end{itemize}
    
    Плоскі алгоритми будують одне розбиття вибірки на кластери. На відміну від них, агломеративні будують цілу систему взаємовкладених кластерів. На виході алгоритму отримується дерево кластерів, коренем якого служить кластер, що містить усі об'єкти вибірки, а листками є найменші кластери з одним об'єктом кожен. В такому разі дослідник має можливість обрати такий переріз дерева, що найкраще відповідатиме його потребам.
    
    Визначені алгоритми однозначно ставлять у відповідність кожному об'єкту один кластер. Невизначені не дають такої чіткої інформації. Замість ідентифікатора кластера вони повертають імовірність, із якою об'єкт належить до кожного із кластерів.
    
    На сьогоднішній день широко використовуються наступні алгоритми кластеризації:
    \begin{itemize}
        \item k-means \cite{Steinhaus, MacQueen}
        \item UPGMA \cite{SokalMichener}
        \item DBSCAN \cite{DBSCAN}
        \item FOREL \cite{Zagorujko}
        \item c-means
        \item карти Кохонена \cite{Rosenblatt}
    \end{itemize}
