\chapter {Аналіз алгоритмів}

    В даній роботі розглядається ефективність чотирьох алгоритмів кластеризації. Два із них плоскі: k-means та DBScan. Інші два ієрархічні: UPGMA та споріднений із ним алгоритм пошуку найближчого сусіда.

\subsection {Опис алгоритмів}
    \paragraph {K-Means}
        K-means -- це метод кластеризації, що повертає таке розбиття, в якому кожен об'єкт належить кластеру із найближчим центром. Задача побудови такого розбиття належить до класу NP \cite{KmeansNpHard}, тому на практиці застосовуються евристичні реалізації.
        Результатом роботи k-means є плоске розбиття. Для роботи алгоритму потрібно заздалегідь володіти інформацією про кількість кластерів, на які розбивається вибірка.
        \begin{algorithm}
            \caption {Алгоритм k-means}
            \begin{enumerate}
                \item[ ] \emph {Ініціалізація.}
                    Виберемо у довільний спосіб $k$ точок $c_1^{(1)}, c_2^{(1)}, ..., c_k^{(1)}$, що стануть центроїдами кластерів.
                \item
                    Заповнюємо кожен із $k$ кластерів тими об'єктами, для яких його центроїда є найближчою з-поміж центроїд усіх кластерів:
                    \[
                        S_i^{(t)} = \{x_j : ||x_j - c_i^{(t)}|| \leq ||x_j - c_{c^*}^{(t)}||, 
                        i^* = 1, 2, ..., k\}
                    \]
                \item
                    Порівняємо розподіл об'єктів по кластерах із отриманим на попередньому кроці.
                    Якщо вони збігаються, алгоритм завершено. В іншому разі, переходимо до кроку 3.
                \item
                    Обчислимо нові центроїди кластерів $c_1^{(t+1)}, c_2^{(t+1)}, ..., c_k^{(t+1)}$ :
                    \[
                        c_i^{(t+1)} = \frac{1} {S_i^{(t)}} \sum_{x_j \in S_i^{(t)}} x_j
                    \]
                    Переходимо до кроку 1.                        
            \end{enumerate}
        \end{algorithm}
        
        Оскільки така реалізація є евристичною, результатом її роботи може стати не глобальне, а локальне розбиття. Зокрема, вони залежать від вибору первинних центроїд кластерів на етапі ініціалізації. До цього моменту є декілька відомих підходів, описаних зокрема в \cite{HamerlyKMeansOptimization}. Можливим варіантом є вибір у якості центроїд випадкових об'єктів із вибірки. Інший варіант -- призначення кожного об'єкта у випадковий кластер та вибір центрів цих кластерів як початкових центроїд.
        
        Стандартною практикою при застосуванні k-means є кількаразовий запуск алгоритму із різними вхідними даними та вибір того результату, який повторюється найчастіше.
